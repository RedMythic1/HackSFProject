[{"url": "https://ace-step.github.io/", "summary": "ACE-Step is a novel open-source foundation model for music generation that bridges the gap between generation speed, musical coherence, and controllability. It integrates diffusion-based generation with Sana's Deep Compression AutoEncoder (DCAE) and a lightweight linear transformer, and leverages MERT and m-hubert to align semantic representations during training. As a result, ACE-Step synthesizes up to 4 minutes of music in just 20 seconds on an A100 GPU, while achieving superior musical coherence and lyric alignment across melody, harmony, and rhythm metrics. ACE-Step preserves fine-grained acoustic details, enabling advanced control mechanisms such as voice cloning, lyric editing, remixing, and track generation. The project aims to establish a foundation model for music AI, a fast, general-purpose, efficient yet flexible architecture that makes it easy to train sub-tasks on top of it. This paves the way for developing powerful tools that seamlessly integrate into the creative workflows of music artists, producers, and content creators.", "is_pdf": false}, {"url": "https://github.com/ace-step/ACE-Step", "summary": "ACE-Step is a novel open-source foundation model for music generation that integrates diffusion-based generation with Sana's Deep Compression AutoEncoder (DCAE) and a lightweight linear transformer. It leverages MERT and m-hubert to align semantic representations during training, enabling rapid convergence. ACE-Step synthesizes up to 4 minutes of music in just 20 seconds on an A100 GPU, 15x faster than LLM-based baselines, while achieving superior musical coherence and lyric alignment across melody, harmony, and rhythm metrics. The model preserves fine-grained acoustic details, enabling advanced control mechanisms such as voice cloning, lyric editing, remixing, and track generation. ACE-Step aims to establish a foundation model for music AI, a fast, general-purpose, efficient yet flexible architecture that makes it easy to train sub-tasks on top of it. The project is licensed under Apache License 2.0 and encourages responsible use to uphold artistic integrity, cultural diversity, and legal compliance.", "is_pdf": false}]