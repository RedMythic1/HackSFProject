{"title": "As an experienced LLM user, I don't use generative LLMs often", "summary": "The text describes a discussion on Hacker News about the use of LLMs in coding tasks. The author, an experienced LLM user, notes that LLMs tend to hallucinate functions and require documentation deep dives, which can be annoying. The author also mentions that coding agents, which are LLMs with code that structures their interactions, can solve the core problem of LLMs setting loose on coding tasks. However, the author notes that the quality of LLMs degrades quickly past the initial reply, even within the context limits. The author suggests that restarting conversations/chats with a new message can help overcome this issue. The text also mentions the use of Context7 and Kagi Assistant, which can search the web for documentation and provide it to the LLM.", "timestamp": 1746489790.963182}