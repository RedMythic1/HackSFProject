{"title": "ACE-Step: A step towards music generation foundation model", "summary": "ACE-Step: A step towards music generation foundation model\n\nACE-Step is an open-source foundation model for music generation that integrates diffusion-based generation with Sana's Deep Compression AutoEncoder (DCAE) and a lightweight linear transformer. It leverages MERT and m-hubert to align semantic representations during training, enabling rapid convergence. ACE-Step synthesizes up to 4 minutes of music in just 20 seconds on an A100 GPU, 15x faster than LLM-based baselines, while achieving superior musical coherence and lyric alignment across melody, harmony, and rhythm metrics. The model preserves fine-grained acoustic details, enabling advanced control mechanisms such as voice cloning, lyric editing, remixing, and track generation. ACE-Step aims to establish a foundation model for music AI, a fast, general-purpose, efficient yet flexible architecture that makes it easy to train sub-tasks on top of it. The project is licensed under Apache License 2.0 and encourages responsible use to uphold artistic integrity, cultural diversity, and legal compliance.", "timestamp": 1746574848.6807308}